<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Comparison of Sensor Performance</title>
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/proj-styles.css">
    <link rel="stylesheet" href="css/bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="css/isotope.css" media="screen" />
    <link rel="stylesheet" href="js/fancybox/jquery.fancybox.css" type="text/css" media="screen" />
    <link rel="stylesheet" type="text/css" href="css/da-slider.css" />
    <link rel="stylesheet" href="css/styles.css" />
    <!-- Font Awesome -->
    <link href="css/font-awesome.min.css" rel="stylesheet">
</head>
<body style="display: flex; flex-direction: column; height: 100vh; margin: 0;">
    <!-- Title Section -->
    <header style="display: flex; justify-content: center; align-items: center; flex: 0 0 15%; width: 100%; margin: 0;">
        <h1 style="font-size: 3vw; text-align: center; margin: 0;">
            Exploring UAS imaging modalities for precision agriculture: predicting table beet root yield and estimating disease severity using multispectral, hyperspectral, and LiDAR sensing
        </h1>
    </header>

    <!-- Main Content Section -->
    <main style="display: flex; flex: 1 0 85%; width: 100%; margin: 0;">
        <!-- Image Section -->
        <div style="flex: 0 0 50%; display: flex; justify-content: center; align-items: center;">
            <img src="projects/pics/sensor_comp.jpg" alt="Sensor Comparison" style="height: auto; width: 90%; max-height: 100%;">
        </div>

        <!-- Buttons and Text Section -->
        <div style="flex: 1; display: flex; flex-direction: column; padding: 20px;">
            <!-- Buttons Section -->
            <div style="flex: 0 0 20%; display: flex; justify-content: center; gap: 10px; align-items: center;">
                <a href="papers/sensor_comp.pdf" target="_blank" style="text-decoration: none;">
                    <button style="padding: 10px 20px; background-color: #5887FF; color: white; border: none; border-radius: 5px; cursor: pointer;">Paper</button>
                </a>
                <a href="https://doi.org/10.1117/12.3054031" target="_blank" style="text-decoration: none;">
                    <button style="padding: 10px 20px; background-color: #5887FF; color: white; border: none; border-radius: 5px; cursor: pointer;">Presentation</button>
                </a>
                <a href="posters/sensor_comp.pdf" target="_blank" style="text-decoration: none;">
                    <button style="padding: 10px 20px; background-color: #5887FF; color: white; border: none; border-radius: 5px; cursor: pointer;">Poster</button>
                </a>
            </div>

            <!-- Text Section -->
            <div style="flex: 1; overflow-y: auto;">
                <h3 style="text-align: justify; margin: 0; font-size: 1.2vw; line-height: 1.6;">Unmanned Aerial Systems (UAS) have become essential tools in precision agriculture, offering flexible sensor integration, high-resolution data, and efficient field coverage. However, comparative evaluations of UAS imaging systems—particularly for root crop yield prediction and disease monitoring—are limited. This study assesses the performance of multispectral (MSI), hyperspectral (HSI), and LiDAR sensing for estimating table beet (Beta vulgaris) root yield and Cercospora Leaf Spot (CLS) severity.

                    Field trials were conducted at Cornell AgriTech (Geneva, NY) during the 2021 and 2022 growing seasons. Data were collected using a five-band MSI sensor (MicaSense RedEdge-M), a VNIR HSI sensor (Headwall Nano, 272 bands), and a Velodyne VLP-16 LiDAR unit. Models were developed using both individual and fused sensor data. The MSI-only model achieved the best root yield prediction (R²<sub>test</sub> = 0.82, MAPE<sub>test</sub> = 15.6%), while HSI+LiDAR achieved R²<sub>test</sub> = 0.79. CLS severity was modeled using vegetation indices and texture metrics, with MSI outperforming HSI (R²<sub>test</sub> = 0.90 vs. 0.87; RMSE<sub>test</sub> = 7.18% vs. 10.1%).
                    
                    Additionally, structural metrics derived via Structure-from-Motion (SfM) proved more informative than LiDAR for yield estimation. These findings highlight the practicality and effectiveness of MSI for both tasks, supporting its use in cost-efficient, scalable precision agriculture workflows.
                    
                    This work provides a comparative framework for sensor selection in UAS-based monitoring and contributes to advancing sustainable, data-driven crop management.
                    
                </h3>
            </div>
        </div>
    </main>
</body>
</html>